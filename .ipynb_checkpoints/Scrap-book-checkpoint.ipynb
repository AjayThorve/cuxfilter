{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba, pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandasHistogram(colName):\n",
    "    return df[colName].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(getCounts('A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import numba\n",
    "from numba import cuda\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def compute_bin(x, n, xmin, xmax):\n",
    "    # special case to mirror NumPy behavior for last bin\n",
    "    if x == xmax:\n",
    "        return n - 1 # a_max always in last bin\n",
    "\n",
    "    # SPEEDTIP: Remove the float64 casts if you don't need to exactly reproduce NumPy\n",
    "    bin = np.int32(n * (np.float64(x) - np.float64(xmin)) / (np.float64(xmax) - np.float64(xmin)))\n",
    "\n",
    "    if bin < 0 or bin >= n:\n",
    "        return None\n",
    "    else:\n",
    "        return bin\n",
    "\n",
    "@cuda.jit\n",
    "def histogram(x, xmin, xmax, histogram_out):\n",
    "    nbins = histogram_out.shape[0]\n",
    "    bin_width = (xmax - xmin) / nbins\n",
    "\n",
    "    start = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "\n",
    "    for i in range(start, x.shape[0], stride):\n",
    "        # note that calling a numba.jit function from CUDA automatically\n",
    "        # compiles an equivalent CUDA device function!\n",
    "        bin_number = compute_bin(x[i], nbins, xmin, xmax)\n",
    "\n",
    "        if bin_number >= 0 and bin_number < histogram_out.shape[0]:\n",
    "            cuda.atomic.add(histogram_out, bin_number, 1)\n",
    "\n",
    "@cuda.jit\n",
    "def min_max(x, min_max_array):\n",
    "    nelements = x.shape[0]\n",
    "\n",
    "    start = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "\n",
    "    # Array already seeded with starting values appropriate for x's dtype\n",
    "    # Not a problem if this array has already been updated\n",
    "    local_min = min_max_array[0]\n",
    "    local_max = min_max_array[1]\n",
    "\n",
    "    for i in range(start, x.shape[0], stride):\n",
    "        element = x[i]\n",
    "        local_min = min(element, local_min)\n",
    "        local_max = max(element, local_max)\n",
    "\n",
    "    # Now combine each thread local min and max\n",
    "    cuda.atomic.min(min_max_array, 0, local_min)\n",
    "    cuda.atomic.max(min_max_array, 1, local_max)\n",
    "\n",
    "\n",
    "def dtype_min_max(dtype):\n",
    "    '''Get the min and max value for a numeric dtype'''\n",
    "    if np.issubdtype(dtype, np.integer):\n",
    "        info = np.iinfo(dtype)\n",
    "    else:\n",
    "        info = np.finfo(dtype)\n",
    "    return info.min, info.max\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def get_bin_edges(a, nbins, a_min, a_max):\n",
    "    bin_edges = np.empty((nbins+1,), dtype=np.float64)\n",
    "    delta = (a_max - a_min) / nbins\n",
    "    for i in range(bin_edges.shape[0]):\n",
    "        bin_edges[i] = a_min + i * delta\n",
    "\n",
    "    bin_edges[-1] = a_max  # Avoid roundoff error on last point\n",
    "    return bin_edges\n",
    "\n",
    "\n",
    "def numba_gpu_histogram(a, bins):\n",
    "    # Move data to GPU so we can do two operations on it\n",
    "    a_gpu = cuda.to_device(a)\n",
    "\n",
    "    ### Find min and max value in array\n",
    "    dtype_min, dtype_max = dtype_min_max(a.dtype)\n",
    "    # Put them in the array in reverse order so that they will be replaced by the first element in the array\n",
    "    min_max_array_gpu = cuda.to_device(np.array([dtype_max, dtype_min], dtype=a.dtype))\n",
    "    min_max[64, 64](a_gpu, min_max_array_gpu)\n",
    "    a_min, a_max = min_max_array_gpu.copy_to_host()\n",
    "\n",
    "    # SPEEDTIP: Skip this step if you don't need to reproduce the NumPy histogram edge array\n",
    "    bin_edges = get_bin_edges(a, bins, a_min, a_max) # Doing this on CPU for now\n",
    "\n",
    "    ### Bin the data into a histogram \n",
    "    histogram_out = cuda.to_device(np.zeros(shape=(bins,), dtype=np.int32))\n",
    "    histogram[64, 64](a_gpu, a_min, a_max, histogram_out)\n",
    "\n",
    "    return histogram_out.copy_to_host(), bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538 ms ± 1.94 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit numba_gpu_histogram(np.asarray(df['B']),1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.98 s ± 130 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pandasHistogram('A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyarrow stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert df to an arrow file that can be saved on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genArrowFile():\n",
    "    df = pd.read_csv('python-scripts/data-100000k.csv')\n",
    "    pa_df = pa.RecordBatch.from_pandas(df)\n",
    "    file = open('temp.arrow', 'wb')\n",
    "    writer = pa.ipc.RecordBatchStreamWriter(file, pa_df.schema)\n",
    "    writer.write_batch(pa_df)\n",
    "    writer.close()\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "genArrowFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write function to read arrow file and return the corresponding pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readArrowToDF():\n",
    "    pa_schema = pa.read_schema(\"temp.arrow\")\n",
    "    print(pa_schema)\n",
    "    pa_df = pa.read_record_batch(\"temp.arrow\",\n",
    "                                 pa_schema)\n",
    "    return pa.RecordBatch.to_pandas(pa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: int64\n",
      "B: int64\n",
      "__index_level_0__: int64\n",
      "metadata\n",
      "--------\n",
      "{b'pandas': b'{\"index_columns\": [\"__index_level_0__\"], \"column_indexes\": [{\"na'\n",
      "            b'me\": null, \"field_name\": null, \"pandas_type\": \"unicode\", \"numpy_'\n",
      "            b'type\": \"object\", \"metadata\": {\"encoding\": \"UTF-8\"}}], \"columns\":'\n",
      "            b' [{\"name\": \"A\", \"field_name\": \"A\", \"pandas_type\": \"int64\", \"nump'\n",
      "            b'y_type\": \"int64\", \"metadata\": null}, {\"name\": \"B\", \"field_name\":'\n",
      "            b' \"B\", \"pandas_type\": \"int64\", \"numpy_type\": \"int64\", \"metadata\":'\n",
      "            b' null}, {\"name\": null, \"field_name\": \"__index_level_0__\", \"panda'\n",
      "            b's_type\": \"int64\", \"numpy_type\": \"int64\", \"metadata\": null}], \"pa'\n",
      "            b'ndas_version\": \"0.22.0\"}'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-29cb12a237bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadArrowToDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-d64436150ca6>\u001b[0m in \u001b[0;36mreadArrowToDF\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mpa_schema\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_schema\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"temp.arrow\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_schema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpa_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_record_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"temp.arrow\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpa_schema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecordBatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mipc.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.read_record_batch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mipc.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.read_message\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mio.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.BufferReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mio.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.py_buffer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "df2 = readArrowToDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.3 s ± 230 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('python-scripts/data-100000k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.75 s ± 56.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit df2['A'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
