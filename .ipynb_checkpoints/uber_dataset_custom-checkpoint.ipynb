{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from shapely.geometry import MultiPoint,mapping\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_dataset = pd.read_csv(\"node_server/uploads/uber-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCentroid(l):\n",
    "    return mapping(MultiPoint(l).centroid)['coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = pd.read_json(\"data/1_censustracts.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating mappings dataframe from the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mappings = pd.DataFrame(columns=[\"id\",\"lat\",\"long\",\"address\"])\n",
    "\n",
    "for key,val in mappings.features.iteritems():\n",
    "    id = val['properties']['MOVEMENT_ID']\n",
    "    lat,long = getCentroid(val['geometry']['coordinates'][0][0])\n",
    "    address = val['properties']['DISPLAY_NAME']\n",
    "    data = np.array([id,lat,long,address])\n",
    "    temp = pd.Series(data,index = [\"id\",\"lat\",\"long\",\"address\"])\n",
    "    df_mappings = df_mappings.append(temp,ignore_index=True)\n",
    "df_mappings['id'] = df_mappings['id'].apply(np.int64)\n",
    "df_mappings['lat'] = df_mappings['lat'].apply(np.float32)\n",
    "df_mappings['long'] = df_mappings['long'].apply(np.float32)\n",
    "df_mappings['address'] = df_mappings['address'].apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_uber_dataset = pd.merge(uber_dataset,df_mappings,how = 'left',left_on ='sourceid', right_on='id');\n",
    "sources_uber_dataset.rename(columns={'lat':'source_lat', 'long':'source_long','address':'source_address'},inplace=True)\n",
    "del sources_uber_dataset['id']\n",
    "\n",
    "dst_uber_dataset = pd.merge(sources_uber_dataset,df_mappings,how = 'left',left_on ='dstid', right_on='id');\n",
    "dst_uber_dataset.rename(columns={'lat':'dst_lat', 'long':'dst_long','address':'dst_address'},inplace=True)\n",
    "del dst_uber_dataset['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sourceid                                      int64\n",
       "dstid                                         int64\n",
       "hod                                           int64\n",
       "mean_travel_time                            float64\n",
       "standard_deviation_travel_time              float64\n",
       "geometric_mean_travel_time                  float64\n",
       "geometric_standard_deviation_travel_time    float64\n",
       "source_lat                                  float64\n",
       "source_long                                 float64\n",
       "source_address                               object\n",
       "dst_lat                                     float64\n",
       "dst_long                                    float64\n",
       "dst_address                                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst_uber_dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_df = pa.RecordBatch.from_pandas(dst_uber_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'node_server/uploads/uber-dataset-final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path+\".arrow\"\n",
    "file = open(path, 'wb')\n",
    "writer = pa.ipc.RecordBatchStreamWriter(file, pa_df.schema)\n",
    "writer.write_batch(pa_df)\n",
    "writer.close()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readArrowToDF(source):\n",
    "    reader = pa.RecordBatchStreamReader(source)\n",
    "    pa_df = reader.read_all()\n",
    "    return pa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = readArrowToDF(\"node_server/uploads/uber-dataset-final.arrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf = df2.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf.to_csv('uber-dataset-final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
